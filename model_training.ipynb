{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, losses, optimizers, activations, metrics, regularizers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# inputs = \n",
    "# expected_outputs = \n",
    "# expected_outputs = expected_outputs[:, 0]\n",
    "# matrix_spikes_inputs = pd.read_csv(\n",
    "#     \"data.csv\", sep=\",\", header=0, usecols=[4, 4]\n",
    "# ).values\n",
    "# matrix_spikes_inputs = matrix_spikes_inputs[:, 0]\n",
    "\n",
    "# new_inputs = np.zeros(((inputs.shape[0]), 16))\n",
    "# for index, spikes in enumerate(matrix_spikes_inputs):\n",
    "#     spike_array = []\n",
    "# for spike in spikes:\n",
    "#     if spike == \"0\":\n",
    "#         spike_array.append(0)\n",
    "#     elif spike == \"1\":\n",
    "#         spike_array.append(1)\n",
    "\n",
    "# new_array = np.append(inputs[index], spike_array)\n",
    "# new_inputs[index] = new_array\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, activation=activations.linear, input_shape=(16,)))\n",
    "model.add(layers.LeakyReLU(0.01))\n",
    "\n",
    "model.add(layers.Dense(32, activation=activations.linear))\n",
    "model.add(layers.LeakyReLU(0.01))\n",
    "\n",
    "model.add(layers.Dense(1, activation=activations.sigmoid))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 300 \n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=metrics.BinaryAccuracy(),\n",
    ")\n",
    "history = model.fit(inputs, expected_outputs, epochs=NUM_EPOCHS, verbose=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and save model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59ffb9c2fdf780c55e40bc1c95813a859e24d9ff464907aae2d00ee66d79bfc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
